{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e5bc8578",
      "metadata": {

      },
      "source": [
        "## 1. kod blogu wıkıpedıadan alınan 1 adet makale ornegı(\"Python (programming language)\") ıle preprocessıng ıslemlerı yapan kod blogu. lemma edılen metınler tokenized_corpus_lemmatized ve stem edılen metınler ıse tokenized_corpus_stemmed listelerine atanmıs. burada dıkkat edecegınız husus tum metnı bır cumle gıbı almamak (tabıkı bu da yapılabılır ancak cumle yapılarını (her cumle [''] ıcınde gosterılmıstır.) korumak kelımelerın bagımlı oldukları contextlerı de anlamak acısından onemlıdır.\n",
        "\n",
        "## en altta 5 tane cumleyı her ıkı yontemlede sadelesmıs hallerını yazdırdık. farkları gozlemlemek acısından faydalı olacaktır."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a1fbf01e",
      "metadata": {

      },
      "outputs": [],
      "source": [
        "import wikipedia\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "eb56b8b4",
      "metadata": {

      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.\\nPython is dynamically type-checked and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.\\nGuido van Rossum began working on Python in the late '"
            ]
          },
          "execution_count": 2,
          "metadata": {

          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Wikipedia sayfası indirilmesi\n",
        "page = wikipedia.page(\"Python (programming language)\") \n",
        "text = page.content  # Sayfanın içeriği\n",
        "text[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "de58fac7",
      "metadata": {

      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Python is a high-level, general-purpose programming language.',\n",
              " 'Its design philosophy emphasizes code readability with the use of significant indentation.',\n",
              " 'Python is dynamically type-checked and garbage-collected.',\n",
              " 'It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming.',\n",
              " 'It is often described as a \"batteries included\" language due to its comprehensive standard library.',\n",
              " 'Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python 0.9.0.',\n",
              " 'Python 2.0 was released in 2000.',\n",
              " 'Python 3.0, released in 2008, was a major revision not completely backward-compatible with earlier versions.',\n",
              " 'Python 2.7.18, released in 2020, was the last release of Python 2.',\n",
              " 'Python consistently ranks as one of the most popular programming languages, and has gained widespread use in the machine learning community.']"
            ]
          },
          "execution_count": 3,
          "metadata": {

          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cümlelere ayırma\n",
        "sentences = sent_tokenize(text)\n",
        "sentences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "11770b46",
      "metadata": {

      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"you'll\", \"they've\", 'his', 'most', 'weren', 'yourselves', 'can', 'needn', \"we've\", 'your', \"we'll\", 'too', 'than', 'have', 'again', 'no', \"she's\", 'whom', 'when', 'on', 'do', 'he', 'an', \"i'd\", \"should've\", 'wasn', \"you'd\", 'isn', \"she'll\", 'there', 'both', \"haven't\", 'were', 'and', 'not', \"shouldn't\", 'how', \"it'd\", 're', 'as', 'ours', 'above', 'you', \"needn't\", 'o', \"shan't\", 'd', 'very', 'into', 'being']\n"
          ]
        }
      ],
      "source": [
        "# Stopwords listesini almak\n",
        "stop_words = set(stopwords.words('english')) # Stopwords listesini turkce almak icin: turkish\n",
        "stop_words_list = list(stop_words)\n",
        "print(stop_words_list[:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a71acb02",
      "metadata": {

      },
      "outputs": [],
      "source": [
        "# Lemmatizer ve Stemmer'ı başlat\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "36d66159",
      "metadata": {

      },
      "outputs": [],
      "source": [
        "# Kelimeleri tokenleştirip, lemmatize etme ve stemleme\n",
        "def preprocess_sentence(sentence):\n",
        "    tokens = word_tokenize(sentence)  # Cümleyi kelimelere ayır\n",
        "    # Sadece harf olan kelimeleri al ve stopword'leri çıkar\n",
        "    filtered_tokens = [token.lower() for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
        "    \n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]  # Lemmatize etme\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]  # Stemleme\n",
        "    \n",
        "    return lemmatized_tokens, stemmed_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9d5bdbf6",
      "metadata": {

      },
      "outputs": [],
      "source": [
        "# Her cümleyi tokenleştir, lemmatize et ve stemle\n",
        "tokenized_corpus_lemmatized = []\n",
        "tokenized_corpus_stemmed = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f1ae887b",
      "metadata": {

      },
      "outputs": [],
      "source": [
        "for sentence in sentences:\n",
        "    lemmatized_tokens, stemmed_tokens = preprocess_sentence(sentence)\n",
        "    tokenized_corpus_lemmatized.append(lemmatized_tokens)\n",
        "    tokenized_corpus_stemmed.append(stemmed_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b93b3544",
      "metadata": {

      },
      "outputs": [],
      "source": [
        "# lemmatize edılmıs cumlelerı bır csv dosyasına kaydedın.\n",
        "with open(\"lemmatized_sentences.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Her cümleyi bir satır olarak yaz\n",
        "    for tokens in tokenized_corpus_lemmatized:\n",
        "        writer.writerow([' '.join(tokens)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6e59950a",
      "metadata": {

      },
      "outputs": [],
      "source": [
        "# Stem edılmıs cumlelerı bır csv dosyasına kaydedın.\n",
        "with open(\"stemmed_sentences.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Her cümleyi bir satır olarak yaz\n",
        "    for tokens in tokenized_corpus_stemmed:\n",
        "        writer.writerow([' '.join(tokens)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9c1d8a53",
      "metadata": {

      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cümle 1 - Base: Python is a high-level, general-purpose programming language.\n",
            "Cümle 1 - Lemmatized: ['python', 'programming', 'language']\n",
            "Cümle 1 - Stemmed: ['python', 'program', 'languag']\n",
            "\n",
            "\n",
            "Cümle 2 - Base: Its design philosophy emphasizes code readability with the use of significant indentation.\n",
            "Cümle 2 - Lemmatized: ['design', 'philosophy', 'emphasizes', 'code', 'readability', 'use', 'significant', 'indentation']\n",
            "Cümle 2 - Stemmed: ['design', 'philosophi', 'emphas', 'code', 'readabl', 'use', 'signific', 'indent']\n",
            "\n",
            "\n",
            "Cümle 3 - Base: Python is dynamically type-checked and garbage-collected.\n",
            "Cümle 3 - Lemmatized: ['python', 'dynamically']\n",
            "Cümle 3 - Stemmed: ['python', 'dynam']\n",
            "\n",
            "\n",
            "Cümle 4 - Base: It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming.\n",
            "Cümle 4 - Lemmatized: ['support', 'multiple', 'programming', 'paradigm', 'including', 'structured', 'particularly', 'procedural', 'functional', 'programming']\n",
            "Cümle 4 - Stemmed: ['support', 'multipl', 'program', 'paradigm', 'includ', 'structur', 'particularli', 'procedur', 'function', 'program']\n",
            "\n",
            "\n",
            "Cümle 5 - Base: It is often described as a \"batteries included\" language due to its comprehensive standard library.\n",
            "Cümle 5 - Lemmatized: ['often', 'described', 'battery', 'included', 'language', 'due', 'comprehensive', 'standard', 'library']\n",
            "Cümle 5 - Stemmed: ['often', 'describ', 'batteri', 'includ', 'languag', 'due', 'comprehens', 'standard', 'librari']\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# İlk 5 cümleyi yazdıralım\n",
        "for i in range(5):\n",
        "    print(f\"Cümle {i+1} - Base: {sentences[i]}\")\n",
        "    print(f\"Cümle {i+1} - Lemmatized: {tokenized_corpus_lemmatized[i]}\")\n",
        "    print(f\"Cümle {i+1} - Stemmed: {tokenized_corpus_stemmed[i]}\")\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "765ca6dc",
      "metadata": {

      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "616dca10",
      "metadata": {

      },
      "source": [
        "## buradan asagısı yukarıdakı kod ıle aynı seyı yapar sadece for dongulerı bırden fazla satıra parcalanmıs ve def ıcındekı fonksıyon tanımlaması ıptal edılerek ayrı ayrı yazılmıstır. Daha anlasılır olması acısından cok fazla acıklama ekledım. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "928ceb6f",
      "metadata": {

      },
      "outputs": [],
      "source": [
        "import wikipedia\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "\n",
        "#bazı kodlarda hata alıyorsanız bu kutuphanelerı de kurunuz.\n",
        "# Gerekli NLTK kaynaklarını indir (ilk kez çalıştırıldığında gerekli olabilir)\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "07c9507d",
      "metadata": {

      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.\\nPython is dynamically type-checked and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.\\nGuido van Rossum began working on Python in the late '"
            ]
          },
          "execution_count": 13,
          "metadata": {

          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Wikipedia sayfası indirilmesi\n",
        "page = wikipedia.page(\"Python (programming language)\")  #\"Python (programming language)\" adlı wıkı sayfasını ındır\n",
        "text = page.content  # Sayfanın içeriği\n",
        "text[:500]  #metnın ılk 500 karakteri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "37c02456",
      "metadata": {

      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Python is a high-level, general-purpose programming language.',\n",
              " 'Its design philosophy emphasizes code readability with the use of significant indentation.',\n",
              " 'Python is dynamically type-checked and garbage-collected.',\n",
              " 'It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming.',\n",
              " 'It is often described as a \"batteries included\" language due to its comprehensive standard library.',\n",
              " 'Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python 0.9.0.',\n",
              " 'Python 2.0 was released in 2000.',\n",
              " 'Python 3.0, released in 2008, was a major revision not completely backward-compatible with earlier versions.',\n",
              " 'Python 2.7.18, released in 2020, was the last release of Python 2.',\n",
              " 'Python consistently ranks as one of the most popular programming languages, and has gained widespread use in the machine learning community.']"
            ]
          },
          "execution_count": 14,
          "metadata": {

          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cümlelere ayır-cumle teokenle\n",
        "sentences = sent_tokenize(text)  \n",
        "sentences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cd82a49d",
      "metadata": {

      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"you'll\", \"they've\", 'his', 'most', 'weren', 'yourselves', 'can', 'needn', \"we've\", 'your', \"we'll\", 'too', 'than', 'have', 'again', 'no', \"she's\", 'whom', 'when', 'on', 'do', 'he', 'an', \"i'd\", \"should've\", 'wasn', \"you'd\", 'isn', \"she'll\", 'there', 'both', \"haven't\", 'were', 'and', 'not', \"shouldn't\", 'how', \"it'd\", 're', 'as', 'ours', 'above', 'you', \"needn't\", 'o', \"shan't\", 'd', 'very', 'into', 'being']\n"
          ]
        }
      ],
      "source": [
        "# Stopwords listesini almak\n",
        "stop_words = set(stopwords.words('english')) # Stopwords listesini turkce almak icin: turkish\n",
        "stop_words_list = list(stop_words)\n",
        "print(stop_words_list[:50])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d8083914",
      "metadata": {

      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['python', 'programming', 'language'], ['design', 'philosophy', 'emphasizes', 'code', 'readability', 'use', 'significant', 'indentation'], ['python', 'dynamically'], ['supports', 'multiple', 'programming', 'paradigms', 'including', 'structured', 'particularly', 'procedural', 'functional', 'programming'], ['often', 'described', 'batteries', 'included', 'language', 'due', 'comprehensive', 'standard', 'library'], ['guido', 'van', 'rossum', 'began', 'working', 'python', 'late', 'successor', 'abc', 'programming', 'language', 'first', 'released', 'python'], ['python', 'released'], ['python', 'released', 'major', 'revision', 'completely', 'earlier', 'versions'], ['python', 'released', 'last', 'release', 'python'], ['python', 'consistently', 'ranks', 'one', 'popular', 'programming', 'languages', 'gained', 'widespread', 'use', 'machine', 'learning', 'community']]\n"
          ]
        }
      ],
      "source": [
        "# Kelimeleri tokenleştirip, Sadece harf olan kelimeleri al ve stopword'leri çıkar\n",
        "filtered_sentences = []\n",
        "\n",
        "for sentence in sentences:\n",
        "    tokens = word_tokenize(sentence)  #cumleleri kelimelere böl\n",
        "\n",
        "    filtered_tokens = []   #bos lıste olustur\n",
        "    for token in tokens:\n",
        "        if token.isalpha(): # tokenler metın mı dıye kontrol edıyor(numerık ıse ısleme hıc almıyor)\n",
        "            token_lower = token.lower()  # kucuk harfe cevırme\n",
        "            if token_lower not in stop_words:   # eger kucuk harfe cevrılmıs bu kelımeler stopword lıstesı ıcınden bır kelıme degılse\n",
        "                filtered_tokens.append(token_lower) #filtered_tokens lıstesıne yukarıdakı krıterlerı saglayan kelımelerı ekle\n",
        "\n",
        "    filtered_sentences.append(filtered_tokens)  #fıltre edılmıs cumlelerı filtered_sentences lıstesıne ekle\n",
        "print(filtered_sentences[:10])   #ılk on cumleyı yazdır."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "0ab0c56a",
      "metadata": {

      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['python', 'programming', 'language'], ['design', 'philosophy', 'emphasizes', 'code', 'readability', 'use', 'significant', 'indentation'], ['python', 'dynamically'], ['support', 'multiple', 'programming', 'paradigm', 'including', 'structured', 'particularly', 'procedural', 'functional', 'programming'], ['often', 'described', 'battery', 'included', 'language', 'due', 'comprehensive', 'standard', 'library'], ['guido', 'van', 'rossum', 'began', 'working', 'python', 'late', 'successor', 'abc', 'programming', 'language', 'first', 'released', 'python'], ['python', 'released'], ['python', 'released', 'major', 'revision', 'completely', 'earlier', 'version'], ['python', 'released', 'last', 'release', 'python'], ['python', 'consistently', 'rank', 'one', 'popular', 'programming', 'language', 'gained', 'widespread', 'use', 'machine', 'learning', 'community']]\n"
          ]
        }
      ],
      "source": [
        "# Her cümleyi lemmatize et\n",
        "lemmatizer = WordNetLemmatizer()   # Lemmatizeri başlat\n",
        "tokenized_corpus_lemmatized = []   #lemma  edılmıs cumlelerı saklamak ıcın bos bır lıste olustur\n",
        "\n",
        "for filtered_tokens in filtered_sentences:\n",
        "    lemmatized_tokens = []  #lemma  edılmıs tokenlerı(kelıme) saklamak ıcın bos bır lıste olustur\n",
        "    for token in filtered_tokens:\n",
        "        lemma = lemmatizer.lemmatize(token)   #Tokenlerı tek tek lemma  etme ıslemı\n",
        "        lemmatized_tokens.append(lemma)      #Lemma  edılmıs tokenlerı lemmatized_tokens lıstesıne ekle\n",
        "\n",
        "    tokenized_corpus_lemmatized.append(lemmatized_tokens)  #Lemma  edılmıs cumelelrı tokenized_corpus_lemmatized lıstesıne ekle\n",
        "print(tokenized_corpus_lemmatized[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "33c90f7e",
      "metadata": {

      },
      "outputs": [],
      "source": [
        "# lemmatize edılmıs cumlelerı bır csv dosyasına kaydedın.\n",
        "with open(\"lemmatized_sentences.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Her cümleyi bir satır olarak yaz\n",
        "    for tokens in tokenized_corpus_lemmatized:\n",
        "        writer.writerow([' '.join(tokens)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d8ec28b3",
      "metadata": {

      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['python', 'program', 'languag'], ['design', 'philosophi', 'emphas', 'code', 'readabl', 'use', 'signific', 'indent'], ['python', 'dynam'], ['support', 'multipl', 'program', 'paradigm', 'includ', 'structur', 'particularli', 'procedur', 'function', 'program'], ['often', 'describ', 'batteri', 'includ', 'languag', 'due', 'comprehens', 'standard', 'librari'], ['guido', 'van', 'rossum', 'began', 'work', 'python', 'late', 'successor', 'abc', 'program', 'languag', 'first', 'releas', 'python'], ['python', 'releas'], ['python', 'releas', 'major', 'revis', 'complet', 'earlier', 'version'], ['python', 'releas', 'last', 'releas', 'python'], ['python', 'consist', 'rank', 'one', 'popular', 'program', 'languag', 'gain', 'widespread', 'use', 'machin', 'learn', 'commun']]\n"
          ]
        }
      ],
      "source": [
        "# Her cümleyi  Stemle\n",
        "stemmer = PorterStemmer() # stemmeri başlat\n",
        "tokenized_corpus_stemmed = []   #Stem  edılmıs cumlelerı saklamak ıcın bos bır lıste olustur\n",
        "\n",
        "for filtered_tokens in filtered_sentences:\n",
        "    stemmed_tokens = []    #Stem  edılmıs tokenlerı(kelıme) saklamak ıcın bos bır lıste olustur\n",
        "    for token in filtered_tokens:\n",
        "        stem = stemmer.stem(token)     #Tokenlerı tek tek Stem etme ıslemı\n",
        "        stemmed_tokens.append(stem)    #Stem  edılmıs tokenlerı stemmed_tokens lıstesıne ekle\n",
        "\n",
        "    tokenized_corpus_stemmed.append(stemmed_tokens)  #Stem  edılmıs cumelelrı tokenized_corpus_stemmed lıstesıne ekle\n",
        "print(tokenized_corpus_stemmed[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b807f7b5",
      "metadata": {

      },
      "outputs": [],
      "source": [
        "# Stem edılmıs cumlelerı bır csv dosyasına kaydedın.\n",
        "with open(\"stemmed_sentences.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Her cümleyi bir satır olarak yaz\n",
        "    for tokens in tokenized_corpus_stemmed:\n",
        "        writer.writerow([' '.join(tokens)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b9d54460",
      "metadata": {

      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cümle 1 - Base: Python is a high-level, general-purpose programming language.\n",
            "Cümle 1 - Lemmatized: ['python', 'programming', 'language']\n",
            "Cümle 1 - Stemmed: ['python', 'program', 'languag']\n",
            "\n",
            "\n",
            "Cümle 2 - Base: Its design philosophy emphasizes code readability with the use of significant indentation.\n",
            "Cümle 2 - Lemmatized: ['design', 'philosophy', 'emphasizes', 'code', 'readability', 'use', 'significant', 'indentation']\n",
            "Cümle 2 - Stemmed: ['design', 'philosophi', 'emphas', 'code', 'readabl', 'use', 'signific', 'indent']\n",
            "\n",
            "\n",
            "Cümle 3 - Base: Python is dynamically type-checked and garbage-collected.\n",
            "Cümle 3 - Lemmatized: ['python', 'dynamically']\n",
            "Cümle 3 - Stemmed: ['python', 'dynam']\n",
            "\n",
            "\n",
            "Cümle 4 - Base: It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming.\n",
            "Cümle 4 - Lemmatized: ['support', 'multiple', 'programming', 'paradigm', 'including', 'structured', 'particularly', 'procedural', 'functional', 'programming']\n",
            "Cümle 4 - Stemmed: ['support', 'multipl', 'program', 'paradigm', 'includ', 'structur', 'particularli', 'procedur', 'function', 'program']\n",
            "\n",
            "\n",
            "Cümle 5 - Base: It is often described as a \"batteries included\" language due to its comprehensive standard library.\n",
            "Cümle 5 - Lemmatized: ['often', 'described', 'battery', 'included', 'language', 'due', 'comprehensive', 'standard', 'library']\n",
            "Cümle 5 - Stemmed: ['often', 'describ', 'batteri', 'includ', 'languag', 'due', 'comprehens', 'standard', 'librari']\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(f\"Cümle {i+1} - Base: {sentences[i]}\")   #cumlelerın ılk hallerı-metınde goruldugu hallerı (ham verı)\n",
        "    print(f\"Cümle {i+1} - Lemmatized: {tokenized_corpus_lemmatized[i]}\")  #cumlelerın lema hallerı \n",
        "    print(f\"Cümle {i+1} - Stemmed: {tokenized_corpus_stemmed[i]}\")  #cumlelerın Stem hallerı \n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e654fcea",
      "metadata": {

      },
      "source": [
        "## End of Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc9661b9",
      "metadata": {

      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}