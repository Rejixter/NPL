import nltk
from nltk.stem import WordNetLemmatizer, PorterStemmer

# === GEREKLÄ° NLTK VERÄ°LERÄ°NÄ° Ä°NDÄ°R ===
required_packages = ['wordnet', 'omw-1.4']
for package in required_packages:
    nltk.download(package)

# === DOSYA AYARLARI ===
input_file = "tokenized_books_summary.txt"    # Ã–nceki Ã§Ä±kan dosya
lemmatized_output = "lemmatized_books_summary.txt"
stemmed_output = "stemmed_books_summary.txt"

# === AraÃ§lar ===
lemmatizer = WordNetLemmatizer()
stemmer = PorterStemmer()

# === TOKENLERÄ° OKU ===
with open(input_file, "r", encoding="utf-8") as f:
    text = f.read()

tokens = text.split()  # BoÅŸluklardan ayÄ±rÄ±p liste yapÄ±yoruz

# === LEMMATIZATION Ä°ÅžLEMÄ° ===
lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]

# === STEMMING Ä°ÅžLEMÄ° ===
stemmed_tokens = [stemmer.stem(token) for token in tokens]

# === SONUÃ‡LARI DOSYALARA KAYDET ===
with open(lemmatized_output, "w", encoding="utf-8") as f:
    f.write(" ".join(lemmatized_tokens))

with open(stemmed_output, "w", encoding="utf-8") as f:
    f.write(" ".join(stemmed_tokens))

print(f"\nâœ… Lemmatization ve Stemming iÅŸlemleri tamamlandÄ±!")
print(f"ðŸ“„ Lemmatized dosya: {lemmatized_output}")
print(f"ðŸ“„ Stemmed dosya: {stemmed_output}")
