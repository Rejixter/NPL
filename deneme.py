from nltk.tokenize import sent_tokenize

text = "This is a sentence. This is another one!"
print(sent_tokenize(text))